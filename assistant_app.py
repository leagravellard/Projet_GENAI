import streamlit as st
from dotenv import load_dotenv
# --- Imports LangChain ---
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper

# --- Charger les variables d'environnement ---
load_dotenv()

# --- CONFIGURATION ---
DB_PATH = "chroma_db"

# --- Initialisation du mod√®le principal ---
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)

# --- Outil RAG : recherche dans la base Chroma ---
def search_documents(query: str) -> str:
    """Recherche dans les documents internes."""
    try:
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        db = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
        retriever = db.as_retriever()
        
        # Cr√©ation du prompt
        prompt = ChatPromptTemplate.from_template("""R√©ponds √† la question suivante en te basant sur le contexte fourni :

Contexte : {context}

Question : {question}

R√©ponse :""")
        
        # Fonction pour formater les documents
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)
        
        # Cr√©ation de la cha√Æne RAG avec LCEL
        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        
        return rag_chain.invoke(query)
    except Exception as e:
        return f"Erreur lors de la recherche dans les documents : {str(e)}"

# --- Autres outils ---
def search_web(query: str) -> str:
    """Recherche sur Internet."""
    try:
        search = DuckDuckGoSearchRun()
        return search.run(query)
    except Exception as e:
        return f"Erreur lors de la recherche web : {str(e)}"

def search_wikipedia(query: str) -> str:
    """Recherche sur Wikipedia."""
    try:
        api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=2000)
        wiki = WikipediaQueryRun(api_wrapper=api_wrapper)
        return wiki.run(query)
    except Exception as e:
        return f"Erreur lors de la recherche Wikipedia : {str(e)}"

def calculate_math(query: str) -> str:
    """Effectue des calculs math√©matiques."""
    try:
        prompt = f"R√©sous ce probl√®me math√©matique et donne uniquement le r√©sultat num√©rique : {query}"
        result = llm.invoke(prompt)
        return result.content
    except Exception as e:
        return f"Erreur de calcul : {str(e)}"

# --- Agent simplifi√© bas√© sur le LLM ---
def agent_query(user_input: str) -> str:
    """Agent qui d√©cide quel outil utiliser et r√©pond."""
    
    system_prompt = """Tu es un assistant intelligent avec acc√®s √† plusieurs outils :

1. search_documents : Pour rechercher dans les documents PDF internes
2. search_web : Pour rechercher des informations r√©centes sur Internet
3. search_wikipedia : Pour des informations encyclop√©diques
4. calculate_math : Pour effectuer des calculs math√©matiques

Pour chaque question :
- Analyse la question
- D√©cide quel outil utiliser (ou si tu peux r√©pondre directement)
- Utilise l'outil si n√©cessaire
- Donne une r√©ponse claire et pr√©cise

Si tu utilises un outil, commence ta r√©ponse par [TOOL: nom_outil] suivi de la requ√™te.
Exemples :
- "[TOOL: search_documents] Quels sont les chiffres de vente ?"
- "[TOOL: search_web] Derni√®res actualit√©s IA"
- "[TOOL: calculate_math] 25 * 4 + 17"
- "[TOOL: search_wikipedia] Albert Einstein"

Si aucun outil n'est n√©cessaire, r√©ponds directement."""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input)
    ]
    
    response = llm.invoke(messages)
    response_text = response.content
    
    # V√©rifier si l'agent veut utiliser un outil
    if "[TOOL:" in response_text:
        tool_start = response_text.find("[TOOL:") + 6
        tool_end = response_text.find("]", tool_start)
        tool_info = response_text[tool_start:tool_end].strip()
        
        # Extraire le nom de l'outil et la requ√™te
        parts = tool_info.split("]", 1)
        if len(parts) == 2:
            tool_name = parts[0].strip()
            tool_query = parts[1].strip()
        else:
            tool_name = tool_info
            tool_query = user_input
        
        # Ex√©cuter l'outil appropri√©
        if "search_documents" in tool_name:
            tool_result = search_documents(tool_query)
        elif "search_web" in tool_name:
            tool_result = search_web(tool_query)
        elif "search_wikipedia" in tool_name:
            tool_result = search_wikipedia(tool_query)
        elif "calculate_math" in tool_name:
            tool_result = calculate_math(tool_query)
        else:
            tool_result = "Outil non reconnu"
        
        # Demander au LLM de formuler la r√©ponse finale
        final_messages = [
            SystemMessage(content="Tu es un assistant qui formule des r√©ponses claires bas√©es sur les r√©sultats des outils."),
            HumanMessage(content=f"Question originale : {user_input}\n\nR√©sultat de l'outil : {tool_result}\n\nFormule une r√©ponse claire et compl√®te.")
        ]
        final_response = llm.invoke(final_messages)
        return final_response.content
    
    return response_text

# --- Interface Streamlit ---
st.set_page_config(page_title="Assistant Intelligent Multi-Comp√©tences", page_icon="ü§ñ")
st.title("ü§ñ Assistant Intelligent Multi-Comp√©tences")
st.caption("Posez-moi des questions sur vos documents, le web, ou effectuez des calculs.")

# --- Historique de chat ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Affichage de l'historique
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Entr√©e utilisateur
if user_query := st.chat_input("Posez votre question ici..."):
    # Ajout du message utilisateur
    st.session_state.messages.append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.markdown(user_query)
    
    # R√©ponse de l'agent
    with st.chat_message("assistant"):
        with st.spinner("R√©flexion..."):
            try:
                answer = agent_query(user_query)
            except Exception as e:
                answer = f"‚ö†Ô∏è Une erreur est survenue : {e}"
            st.markdown(answer)
    
    # Sauvegarde de la r√©ponse
    st.session_state.messages.append({"role": "assistant", "content": answer})