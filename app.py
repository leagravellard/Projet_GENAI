import streamlit as st
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

# Charger les variables d'environnement
load_dotenv()

# D√©finir le chemin de la base de donn√©es
DB_PATH = "chroma_db"


def format_docs(docs):
    """Helper function to format documents for the prompt."""
    return "\n\n".join(doc.page_content for doc in docs)


def main():
    # --- Configuration de la page Streamlit ---
    st.set_page_config(page_title="Assistant de Documents", page_icon="üìÑ")
    st.title("üìÑ Assistant Intelligent (RAG)")
    st.caption("Posez des questions sur le contenu de vos documents PDF.")

    # --- Chargement de la base de donn√©es vectorielle ---
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    db = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)

    # --- Cr√©ation de la cha√Æne de traitement (style LCEL) ---
    retriever = db.as_retriever()
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

    # Template de prompt pour guider le LLM
    template = """
    Vous √™tes un assistant sp√©cialis√© dans la r√©ponse aux questions bas√©es sur des documents.
    Utilisez les morceaux de contexte suivants pour r√©pondre √† la question √† la fin.
    Si vous ne connaissez pas la r√©ponse, dites simplement que vous ne savez pas, n'essayez pas d'inventer une r√©ponse.
    Gardez la r√©ponse concise et informative.

    Contexte:
    {context}

    Question:
    {question}

    R√©ponse utile:
    """
    prompt = ChatPromptTemplate.from_template(template)

    # Cr√©ation de la cha√Æne LCEL
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )

    # --- Interface utilisateur ---
    query = st.text_input(
        "Posez votre question ici :",
        placeholder="Ex : Quel est le sujet principal du rapport X ?"
    )

    if query:
        with st.spinner("Recherche de la r√©ponse dans les documents..."):
            # On ex√©cute la cha√Æne avec la question de l'utilisateur
            answer = rag_chain.invoke(query)

            # Affichage de la r√©ponse
            st.header("R√©ponse")
            st.write(answer)

            # Affichage des sources (retrouv√©es par le retriever)
            with st.expander("Afficher les sources utilis√©es"):
                source_documents = retriever.invoke(query)
                for document in source_documents:
                    st.info(
                        f"Source : {document.metadata['source']} "
                        f"(Page : {document.metadata.get('page', 'N/A')})"
                    )
                    st.write(document.page_content)


if __name__ == "__main__":
    main()
